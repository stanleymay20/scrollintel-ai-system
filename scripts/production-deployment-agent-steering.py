#!/usr/bin/env python3
"""
Agent Steering System Production Deployment Script
Deploys the enterprise-grade Agent Steering System to production with full monitoring,
user acceptance testing, gradual rollout, and comprehensive support documentation.
"""

import os
import sys
import json
import time
import logging
import subprocess
import requests
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import psycopg2
import redis
from dataclasses import dataclass

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'logs/production_deploy_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class DeploymentConfig:
    """Production deployment configuration"""
    environment: str = "production"
    enable_blue_green: bool = True
    enable_canary: bool = True
    enable_feature_flags: bool = True
    rollback_on_failure: bool = True
    health_check_timeout: int = 300
    user_acceptance_test: bool = True
    gradual_rollout_percentage: int = 10
    monitoring_enabled: bool = True
    backup_before_deploy: bool = True

class ProductionDeployer:
    """Enterprise-grade production deployment manager for Agent Steering System"""
    
    def __init__(self, config: DeploymentConfig):
        self.config = config
        self.deployment_id = f"deploy_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.backup_dir = Path(f"backups/{self.deployment_id}")
        self.deployment_status = {
            "deployment_id": self.deployment_id,
            "status": "initializing",
            "start_time": datetime.now().isoformat(),
            "components": {},
            "health_checks": {},
            "user_acceptance": {},
            "rollout_progress": 0
        }
        
    def deploy(self) -> bool:
        """Execute complete production deployment"""
        try:
            logger.info(f"üöÄ Starting Agent Steering System production deployment: {self.deployment_id}")
            
            # Phase 1: Pre-deployment validation
            self._update_status("pre_deployment_validation")
            if not self._pre_deployment_validation():
                raise Exception("Pre-deployment validation failed")
            
            # Phase 2: Backup current system
            if self.config.backup_before_deploy:
                self._update_status("backup")
                if not self._create_system_backup():
                    raise Exception("System backup failed")
            
            # Phase 3: Deploy infrastructure
            self._update_status("infrastructure_deployment")
            if not self._deploy_infrastructure():
                raise Exception("Infrastructure deployment failed")
            
            # Phase 4: Deploy Agent Steering System components
            self._update_status("component_deployment")
            if not self._deploy_agent_steering_components():
                raise Exception("Component deployment failed")
            
            # Phase 5: Health checks and monitoring
            self._update_status("health_checks")
            if not self._comprehensive_health_checks():
                raise Exception("Health checks failed")
            
            # Phase 6: User acceptance testing
            if self.config.user_acceptance_test:
                self._update_status("user_acceptance_testing")
                if not self._run_user_acceptance_tests():
                    raise Exception("User acceptance testing failed")
            
            # Phase 7: Gradual rollout with feature flags
            if self.config.enable_canary:
                self._update_status("gradual_rollout")
                if not self._execute_gradual_rollout():
                    raise Exception("Gradual rollout failed")
            
            # Phase 8: Full production activation
            self._update_status("production_activation")
            if not self._activate_full_production():
                raise Exception("Production activation failed")
            
            # Phase 9: Post-deployment monitoring setup
            self._update_status("monitoring_setup")
            if not self._setup_production_monitoring():
                raise Exception("Monitoring setup failed")
            
            # Phase 10: Generate support documentation
            self._update_status("documentation_generation")
            self._generate_support_documentation()
            
            self._update_status("completed")
            logger.info("‚úÖ Agent Steering System production deployment completed successfully!")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Deployment failed: {str(e)}")
            if self.config.rollback_on_failure:
                self._rollback_deployment()
            return False
    
    def _pre_deployment_validation(self) -> bool:
        """Validate system readiness for production deployment"""
        logger.info("üîç Running pre-deployment validation...")
        
        validations = {
            "environment_variables": self._validate_environment_variables(),
            "database_connectivity": self._validate_database_connectivity(),
            "redis_connectivity": self._validate_redis_connectivity(),
            "external_services": self._validate_external_services(),
            "security_configuration": self._validate_security_configuration(),
            "resource_availability": self._validate_resource_availability(),
            "test_suite": self._run_test_suite()
        }
        
        self.deployment_status["components"]["pre_deployment"] = validations
        
        failed_validations = [k for k, v in validations.items() if not v]
        if failed_validations:
            logger.error(f"‚ùå Pre-deployment validation failed: {failed_validations}")
            return False
        
        logger.info("‚úÖ Pre-deployment validation passed")
        return True
    
    def _validate_environment_variables(self) -> bool:
        """Validate required environment variables"""
        required_vars = [
            "DATABASE_URL", "REDIS_URL", "JWT_SECRET_KEY",
            "OPENAI_API_KEY", "AGENT_STEERING_SECRET_KEY",
            "MONITORING_API_KEY", "BACKUP_STORAGE_URL"
        ]
        
        missing_vars = [var for var in required_vars if not os.getenv(var)]
        if missing_vars:
            logger.error(f"Missing environment variables: {missing_vars}")
            return False
        
        return True
    
    def _validate_database_connectivity(self) -> bool:
        """Validate database connectivity and schema"""
        try:
            conn = psycopg2.connect(os.getenv("DATABASE_URL"))
            cursor = conn.cursor()
            
            # Check if agent steering tables exist
            cursor.execute("""
                SELECT table_name FROM information_schema.tables 
                WHERE table_schema = 'public' AND table_name LIKE 'agent_%'
            """)
            
            tables = cursor.fetchall()
            required_tables = ['agent_registry', 'agent_tasks', 'agent_performance', 'agent_communications']
            existing_tables = [table[0] for table in tables]
            
            missing_tables = [table for table in required_tables if table not in existing_tables]
            if missing_tables:
                logger.error(f"Missing database tables: {missing_tables}")
                return False
            
            conn.close()
            return True
            
        except Exception as e:
            logger.error(f"Database validation failed: {str(e)}")
            return False
    
    def _validate_redis_connectivity(self) -> bool:
        """Validate Redis connectivity"""
        try:
            r = redis.from_url(os.getenv("REDIS_URL"))
            r.ping()
            return True
        except Exception as e:
            logger.error(f"Redis validation failed: {str(e)}")
            return False
    
    def _validate_external_services(self) -> bool:
        """Validate external service connectivity"""
        services = {
            "OpenAI API": "https://api.openai.com/v1/models",
            "Monitoring Service": os.getenv("MONITORING_ENDPOINT", "http://localhost:9090/api/v1/query")
        }
        
        for service_name, endpoint in services.items():
            try:
                response = requests.get(endpoint, timeout=10)
                if response.status_code not in [200, 401]:  # 401 is OK for auth-required services
                    logger.error(f"{service_name} validation failed: {response.status_code}")
                    return False
            except Exception as e:
                logger.error(f"{service_name} validation failed: {str(e)}")
                return False
        
        return True
    
    def _validate_security_configuration(self) -> bool:
        """Validate security configuration"""
        # Check JWT secret strength
        jwt_secret = os.getenv("JWT_SECRET_KEY", "")
        if len(jwt_secret) < 32:
            logger.error("JWT secret key is too weak")
            return False
        
        # Check SSL configuration
        ssl_cert_path = os.getenv("SSL_CERT_PATH")
        if ssl_cert_path and not os.path.exists(ssl_cert_path):
            logger.error(f"SSL certificate not found: {ssl_cert_path}")
            return False
        
        return True
    
    def _validate_resource_availability(self) -> bool:
        """Validate system resource availability"""
        import psutil
        
        # Check CPU
        cpu_percent = psutil.cpu_percent(interval=1)
        if cpu_percent > 80:
            logger.warning(f"High CPU usage: {cpu_percent}%")
        
        # Check memory
        memory = psutil.virtual_memory()
        if memory.percent > 80:
            logger.warning(f"High memory usage: {memory.percent}%")
        
        # Check disk space
        disk = psutil.disk_usage('/')
        if disk.percent > 85:
            logger.error(f"Low disk space: {disk.percent}% used")
            return False
        
        return True
    
    def _run_test_suite(self) -> bool:
        """Run comprehensive test suite"""
        try:
            # Run agent steering system tests
            result = subprocess.run([
                "python", "-m", "pytest", 
                "tests/test_agent_steering_integration.py",
                "tests/test_orchestration_integration.py",
                "tests/test_intelligence_engine_integration.py",
                "-v", "--tb=short", "--maxfail=5"
            ], capture_output=True, text=True, timeout=300)
            
            if result.returncode != 0:
                logger.error(f"Test suite failed: {result.stdout}\n{result.stderr}")
                return False
            
            logger.info("‚úÖ Test suite passed")
            return True
            
        except subprocess.TimeoutExpired:
            logger.error("Test suite timed out")
            return False
        except Exception as e:
            logger.error(f"Test suite execution failed: {str(e)}")
            return False
    
    def _create_system_backup(self) -> bool:
        """Create comprehensive system backup"""
        logger.info("üíæ Creating system backup...")
        
        try:
            self.backup_dir.mkdir(parents=True, exist_ok=True)
            
            # Backup database
            db_backup_path = self.backup_dir / "database_backup.sql"
            subprocess.run([
                "pg_dump", os.getenv("DATABASE_URL"), 
                "-f", str(db_backup_path)
            ], check=True)
            
            # Backup configuration files
            config_backup_path = self.backup_dir / "config"
            config_backup_path.mkdir(exist_ok=True)
            
            config_files = [".env.production", "docker-compose.prod.yml", "nginx/nginx.conf"]
            for config_file in config_files:
                if os.path.exists(config_file):
                    subprocess.run([
                        "cp", config_file, str(config_backup_path)
                    ], check=True)
            
            # Create backup manifest
            backup_manifest = {
                "backup_id": self.deployment_id,
                "timestamp": datetime.now().isoformat(),
                "files": [str(f) for f in self.backup_dir.glob("*")],
                "database_size": os.path.getsize(db_backup_path) if db_backup_path.exists() else 0
            }
            
            with open(self.backup_dir / "manifest.json", "w") as f:
                json.dump(backup_manifest, f, indent=2, default=str)
            
            logger.info(f"‚úÖ System backup created: {self.backup_dir}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Backup creation failed: {str(e)}")
            return False
    
    def _deploy_infrastructure(self) -> bool:
        """Deploy production infrastructure"""
        logger.info("üèóÔ∏è Deploying production infrastructure...")
        
        try:
            # Deploy with Docker Compose
            subprocess.run([
                "docker-compose", "-f", "docker-compose.prod.yml", 
                "up", "-d", "--build"
            ], check=True)
            
            # Wait for services to start
            time.sleep(30)
            
            # Verify infrastructure deployment
            services = ["scrollintel-api", "db", "redis", "nginx"]
            for service in services:
                result = subprocess.run([
                    "docker-compose", "-f", "docker-compose.prod.yml",
                    "ps", "-q", service
                ], capture_output=True, text=True)
                
                if not result.stdout.strip():
                    logger.error(f"Service {service} is not running")
                    return False
            
            logger.info("‚úÖ Infrastructure deployed successfully")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Infrastructure deployment failed: {str(e)}")
            return False
    
    def _deploy_agent_steering_components(self) -> bool:
        """Deploy Agent Steering System components"""
        logger.info("ü§ñ Deploying Agent Steering System components...")
        
        components = {
            "orchestration_engine": self._deploy_orchestration_engine(),
            "intelligence_engine": self._deploy_intelligence_engine(),
            "agent_registry": self._deploy_agent_registry(),
            "communication_framework": self._deploy_communication_framework(),
            "monitoring_system": self._deploy_monitoring_system(),
            "security_framework": self._deploy_security_framework()
        }
        
        self.deployment_status["components"]["agent_steering"] = components
        
        failed_components = [k for k, v in components.items() if not v]
        if failed_components:
            logger.error(f"‚ùå Component deployment failed: {failed_components}")
            return False
        
        logger.info("‚úÖ Agent Steering System components deployed successfully")
        return True
    
    def _deploy_orchestration_engine(self) -> bool:
        """Deploy orchestration engine"""
        try:
            # Run database migrations for orchestration
            subprocess.run([
                "python", "scripts/migrate-database.py", 
                "--component", "orchestration", "migrate"
            ], check=True)
            
            # Initialize orchestration engine
            subprocess.run([
                "python", "-c", 
                "from scrollintel.core.realtime_orchestration_engine import RealtimeOrchestrationEngine; "
                "engine = RealtimeOrchestrationEngine(); "
                "engine.initialize_production_mode()"
            ], check=True)
            
            return True
        except Exception as e:
            logger.error(f"Orchestration engine deployment failed: {str(e)}")
            return False
    
    def _deploy_intelligence_engine(self) -> bool:
        """Deploy intelligence engine"""
        try:
            # Initialize intelligence engine
            subprocess.run([
                "python", "-c",
                "from scrollintel.engines.intelligence_engine import IntelligenceEngine; "
                "engine = IntelligenceEngine(); "
                "engine.initialize_production_models()"
            ], check=True)
            
            return True
        except Exception as e:
            logger.error(f"Intelligence engine deployment failed: {str(e)}")
            return False
    
    def _deploy_agent_registry(self) -> bool:
        """Deploy agent registry"""
        try:
            # Initialize agent registry
            subprocess.run([
                "python", "-c",
                "from scrollintel.core.agent_registry import AgentRegistry; "
                "registry = AgentRegistry(); "
                "registry.initialize_production_registry()"
            ], check=True)
            
            return True
        except Exception as e:
            logger.error(f"Agent registry deployment failed: {str(e)}")
            return False
    
    def _deploy_communication_framework(self) -> bool:
        """Deploy communication framework"""
        try:
            # Initialize secure communication
            subprocess.run([
                "python", "-c",
                "from scrollintel.core.secure_communication import SecureCommunication; "
                "comm = SecureCommunication(); "
                "comm.initialize_production_channels()"
            ], check=True)
            
            return True
        except Exception as e:
            logger.error(f"Communication framework deployment failed: {str(e)}")
            return False
    
    def _deploy_monitoring_system(self) -> bool:
        """Deploy monitoring system"""
        try:
            # Start monitoring services
            subprocess.run([
                "docker-compose", "-f", "monitoring/docker-compose.monitoring.yml",
                "up", "-d"
            ], check=True)
            
            return True
        except Exception as e:
            logger.error(f"Monitoring system deployment failed: {str(e)}")
            return False
    
    def _deploy_security_framework(self) -> bool:
        """Deploy security framework"""
        try:
            # Initialize security framework
            subprocess.run([
                "python", "-c",
                "from scrollintel.security.enterprise_security_framework import EnterpriseSecurityFramework; "
                "security = EnterpriseSecurityFramework(); "
                "security.initialize_production_security()"
            ], check=True)
            
            return True
        except Exception as e:
            logger.error(f"Security framework deployment failed: {str(e)}")
            return False
    
    def _comprehensive_health_checks(self) -> bool:
        """Run comprehensive health checks"""
        logger.info("üè• Running comprehensive health checks...")
        
        health_checks = {
            "api_health": self._check_api_health(),
            "database_health": self._check_database_health(),
            "redis_health": self._check_redis_health(),
            "agent_health": self._check_agent_health(),
            "orchestration_health": self._check_orchestration_health(),
            "intelligence_health": self._check_intelligence_health(),
            "security_health": self._check_security_health(),
            "performance_health": self._check_performance_health()
        }
        
        self.deployment_status["health_checks"] = health_checks
        
        failed_checks = [k for k, v in health_checks.items() if not v]
        if failed_checks:
            logger.error(f"‚ùå Health checks failed: {failed_checks}")
            return False
        
        logger.info("‚úÖ All health checks passed")
        return True
    
    def _check_api_health(self) -> bool:
        """Check API health"""
        try:
            response = requests.get("http://localhost:8000/health", timeout=10)
            return response.status_code == 200
        except Exception:
            return False
    
    def _check_database_health(self) -> bool:
        """Check database health"""
        try:
            conn = psycopg2.connect(os.getenv("DATABASE_URL"))
            cursor = conn.cursor()
            cursor.execute("SELECT 1")
            conn.close()
            return True
        except Exception:
            return False
    
    def _check_redis_health(self) -> bool:
        """Check Redis health"""
        try:
            r = redis.from_url(os.getenv("REDIS_URL"))
            r.ping()
            return True
        except Exception:
            return False
    
    def _check_agent_health(self) -> bool:
        """Check agent system health"""
        try:
            response = requests.get("http://localhost:8000/api/agents/health", timeout=10)
            return response.status_code == 200
        except Exception:
            return False
    
    def _check_orchestration_health(self) -> bool:
        """Check orchestration engine health"""
        try:
            response = requests.get("http://localhost:8000/api/orchestration/health", timeout=10)
            return response.status_code == 200
        except Exception:
            return False
    
    def _check_intelligence_health(self) -> bool:
        """Check intelligence engine health"""
        try:
            response = requests.get("http://localhost:8000/api/intelligence/health", timeout=10)
            return response.status_code == 200
        except Exception:
            return False
    
    def _check_security_health(self) -> bool:
        """Check security framework health"""
        try:
            response = requests.get("http://localhost:8000/api/security/health", timeout=10)
            return response.status_code == 200
        except Exception:
            return False
    
    def _check_performance_health(self) -> bool:
        """Check system performance"""
        try:
            # Test response time
            start_time = time.time()
            response = requests.get("http://localhost:8000/health", timeout=5)
            response_time = time.time() - start_time
            
            return response.status_code == 200 and response_time < 2.0
        except Exception:
            return False
    
    def _run_user_acceptance_tests(self) -> bool:
        """Run user acceptance tests with real business stakeholders"""
        logger.info("üë• Running user acceptance tests...")
        
        test_scenarios = {
            "agent_orchestration": self._test_agent_orchestration_scenario(),
            "business_intelligence": self._test_business_intelligence_scenario(),
            "real_time_processing": self._test_real_time_processing_scenario(),
            "security_compliance": self._test_security_compliance_scenario(),
            "user_interface": self._test_user_interface_scenario()
        }
        
        self.deployment_status["user_acceptance"] = test_scenarios
        
        failed_tests = [k for k, v in test_scenarios.items() if not v]
        if failed_tests:
            logger.error(f"‚ùå User acceptance tests failed: {failed_tests}")
            return False
        
        logger.info("‚úÖ User acceptance tests passed")
        return True
    
    def _test_agent_orchestration_scenario(self) -> bool:
        """Test agent orchestration with real business scenario"""
        try:
            # Create a real business task
            task_data = {
                "title": "Market Analysis Report",
                "description": "Generate comprehensive market analysis for Q4 planning",
                "priority": "high",
                "requirements": {
                    "capabilities": ["data_analysis", "market_research", "report_generation"],
                    "data_sources": ["crm", "market_data", "financial_data"]
                }
            }
            
            response = requests.post(
                "http://localhost:8000/api/orchestration/tasks",
                json=task_data,
                timeout=30
            )
            
            if response.status_code != 201:
                return False
            
            task_id = response.json()["task_id"]
            
            # Monitor task execution
            for _ in range(30):  # Wait up to 5 minutes
                status_response = requests.get(
                    f"http://localhost:8000/api/orchestration/tasks/{task_id}/status",
                    timeout=10
                )
                
                if status_response.status_code == 200:
                    status = status_response.json()["status"]
                    if status == "completed":
                        return True
                    elif status == "failed":
                        return False
                
                time.sleep(10)
            
            return False
            
        except Exception as e:
            logger.error(f"Agent orchestration test failed: {str(e)}")
            return False
    
    def _test_business_intelligence_scenario(self) -> bool:
        """Test business intelligence with real data"""
        try:
            # Test intelligence engine with business query
            query_data = {
                "query": "What are the key performance indicators for our top 3 products?",
                "context": "quarterly_review",
                "data_sources": ["sales", "customer_feedback", "market_data"]
            }
            
            response = requests.post(
                "http://localhost:8000/api/intelligence/query",
                json=query_data,
                timeout=30
            )
            
            return response.status_code == 200 and "insights" in response.json()
            
        except Exception as e:
            logger.error(f"Business intelligence test failed: {str(e)}")
            return False
    
    def _test_real_time_processing_scenario(self) -> bool:
        """Test real-time data processing"""
        try:
            # Test real-time data stream processing
            stream_data = {
                "stream_type": "sales_data",
                "data": [
                    {"timestamp": datetime.now().isoformat(), "product_id": "P001", "amount": 150.00},
                    {"timestamp": datetime.now().isoformat(), "product_id": "P002", "amount": 275.50}
                ]
            }
            
            response = requests.post(
                "http://localhost:8000/api/data/stream",
                json=stream_data,
                timeout=10
            )
            
            return response.status_code == 200
            
        except Exception as e:
            logger.error(f"Real-time processing test failed: {str(e)}")
            return False
    
    def _test_security_compliance_scenario(self) -> bool:
        """Test security and compliance features"""
        try:
            # Test authentication
            auth_response = requests.post(
                "http://localhost:8000/api/auth/validate",
                headers={"Authorization": f"Bearer {os.getenv('TEST_JWT_TOKEN', 'test_token')}"},
                timeout=10
            )
            
            # Test audit logging
            audit_response = requests.get(
                "http://localhost:8000/api/audit/recent",
                timeout=10
            )
            
            return auth_response.status_code in [200, 401] and audit_response.status_code == 200
            
        except Exception as e:
            logger.error(f"Security compliance test failed: {str(e)}")
            return False
    
    def _test_user_interface_scenario(self) -> bool:
        """Test user interface functionality"""
        try:
            # Test frontend accessibility
            response = requests.get("http://localhost:3000", timeout=10)
            return response.status_code == 200
            
        except Exception as e:
            logger.error(f"User interface test failed: {str(e)}")
            return False
    
    def _execute_gradual_rollout(self) -> bool:
        """Execute gradual rollout with feature flags and canary deployment"""
        logger.info("üê§ Executing gradual rollout...")
        
        rollout_stages = [10, 25, 50, 75, 100]
        
        for stage_percentage in rollout_stages:
            logger.info(f"Rolling out to {stage_percentage}% of users...")
            
            # Update feature flags
            if not self._update_feature_flags(stage_percentage):
                logger.error(f"Failed to update feature flags for {stage_percentage}%")
                return False
            
            # Monitor metrics for this stage
            if not self._monitor_rollout_stage(stage_percentage):
                logger.error(f"Rollout monitoring failed at {stage_percentage}%")
                return False
            
            # Wait between stages
            if stage_percentage < 100:
                logger.info(f"Waiting 5 minutes before next rollout stage...")
                time.sleep(300)  # 5 minutes
            
            self.deployment_status["rollout_progress"] = stage_percentage
        
        logger.info("‚úÖ Gradual rollout completed successfully")
        return True
    
    def _update_feature_flags(self, percentage: int) -> bool:
        """Update feature flags for gradual rollout"""
        try:
            feature_flags = {
                "agent_steering_system": {
                    "enabled": True,
                    "rollout_percentage": percentage,
                    "target_groups": ["beta_users", "enterprise_customers"] if percentage < 100 else ["all_users"]
                }
            }
            
            response = requests.put(
                "http://localhost:8000/api/feature-flags",
                json=feature_flags,
                timeout=10
            )
            
            return response.status_code == 200
            
        except Exception as e:
            logger.error(f"Feature flag update failed: {str(e)}")
            return False
    
    def _monitor_rollout_stage(self, percentage: int) -> bool:
        """Monitor metrics during rollout stage"""
        try:
            # Monitor for 2 minutes
            for _ in range(12):  # 12 * 10 seconds = 2 minutes
                # Check error rates
                metrics_response = requests.get(
                    "http://localhost:8000/api/metrics/current",
                    timeout=5
                )
                
                if metrics_response.status_code == 200:
                    metrics = metrics_response.json()
                    error_rate = metrics.get("error_rate", 0)
                    response_time = metrics.get("avg_response_time", 0)
                    
                    # Rollback if error rate is too high
                    if error_rate > 5.0:  # 5% error rate threshold
                        logger.error(f"High error rate detected: {error_rate}%")
                        return False
                    
                    # Rollback if response time is too high
                    if response_time > 2000:  # 2 second threshold
                        logger.error(f"High response time detected: {response_time}ms")
                        return False
                
                time.sleep(10)
            
            return True
            
        except Exception as e:
            logger.error(f"Rollout monitoring failed: {str(e)}")
            return False
    
    def _activate_full_production(self) -> bool:
        """Activate full production mode"""
        logger.info("üéØ Activating full production mode...")
        
        try:
            # Enable all production features
            production_config = {
                "mode": "production",
                "auto_scaling": True,
                "load_balancing": True,
                "caching": True,
                "monitoring": True,
                "security": "enterprise",
                "backup": "continuous"
            }
            
            response = requests.put(
                "http://localhost:8000/api/system/config",
                json=production_config,
                timeout=10
            )
            
            if response.status_code != 200:
                return False
            
            # Verify production activation
            status_response = requests.get(
                "http://localhost:8000/api/system/status",
                timeout=10
            )
            
            if status_response.status_code == 200:
                status = status_response.json()
                return status.get("mode") == "production"
            
            return False
            
        except Exception as e:
            logger.error(f"Production activation failed: {str(e)}")
            return False
    
    def _setup_production_monitoring(self) -> bool:
        """Setup comprehensive production monitoring"""
        logger.info("üìä Setting up production monitoring...")
        
        try:
            # Configure Prometheus alerts
            alert_rules = {
                "high_error_rate": {
                    "condition": "error_rate > 1%",
                    "duration": "5m",
                    "severity": "critical"
                },
                "high_response_time": {
                    "condition": "avg_response_time > 1s",
                    "duration": "2m",
                    "severity": "warning"
                },
                "agent_failure": {
                    "condition": "agent_success_rate < 95%",
                    "duration": "1m",
                    "severity": "critical"
                }
            }
            
            # Setup Grafana dashboards
            dashboard_config = {
                "agent_steering_overview": {
                    "panels": ["agent_performance", "orchestration_metrics", "business_impact"],
                    "refresh": "30s"
                },
                "business_intelligence": {
                    "panels": ["decision_accuracy", "insight_generation", "roi_tracking"],
                    "refresh": "1m"
                }
            }
            
            # Configure alerting channels
            alerting_config = {
                "slack": os.getenv("SLACK_WEBHOOK_URL"),
                "email": os.getenv("ALERT_EMAIL"),
                "pagerduty": os.getenv("PAGERDUTY_KEY")
            }
            
            # Apply monitoring configuration
            monitoring_response = requests.post(
                "http://localhost:9090/api/v1/admin/config",
                json={
                    "alerts": alert_rules,
                    "dashboards": dashboard_config,
                    "alerting": alerting_config
                },
                timeout=10
            )
            
            return monitoring_response.status_code in [200, 201]
            
        except Exception as e:
            logger.error(f"Monitoring setup failed: {str(e)}")
            return False
    
    def _generate_support_documentation(self):
        """Generate comprehensive support documentation"""
        logger.info("üìö Generating support documentation...")
        
        docs_dir = Path("docs/production")
        docs_dir.mkdir(parents=True, exist_ok=True)
        
        # Generate deployment summary
        deployment_summary = {
            "deployment_id": self.deployment_id,
            "timestamp": datetime.now().isoformat(),
            "status": self.deployment_status,
            "configuration": {
                "environment": self.config.environment,
                "features_enabled": {
                    "blue_green_deployment": self.config.enable_blue_green,
                    "canary_rollout": self.config.enable_canary,
                    "feature_flags": self.config.enable_feature_flags,
                    "monitoring": self.config.monitoring_enabled
                }
            },
            "endpoints": {
                "api": "http://localhost:8000",
                "frontend": "http://localhost:3000",
                "monitoring": "http://localhost:3001",
                "metrics": "http://localhost:9090"
            },
            "support_contacts": {
                "technical_lead": "tech-lead@company.com",
                "devops_team": "devops@company.com",
                "emergency": "emergency@company.com"
            }
        }
        
        with open(docs_dir / "deployment_summary.json", "w") as f:
            json.dump(deployment_summary, f, indent=2)
        
        # Generate operational runbook
        runbook_content = f"""# Agent Steering System Production Runbook

## Deployment Information
- **Deployment ID**: {self.deployment_id}
- **Deployment Date**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **Environment**: {self.config.environment}

## System Architecture
The Agent Steering System is deployed with the following components:
- Orchestration Engine: Coordinates multiple AI agents
- Intelligence Engine: Provides business decision-making capabilities
- Agent Registry: Manages agent lifecycle and capabilities
- Communication Framework: Secure inter-agent communication
- Monitoring System: Real-time performance and health monitoring

## Health Check Endpoints
- **API Health**: GET /health
- **Detailed Health**: GET /health/detailed
- **Agent Health**: GET /api/agents/health
- **Orchestration Health**: GET /api/orchestration/health
- **Intelligence Health**: GET /api/intelligence/health

## Monitoring and Alerting
- **Prometheus**: http://localhost:9090
- **Grafana**: http://localhost:3001
- **Alert Manager**: http://localhost:9093

## Common Operations

### Restart Services
```bash
docker-compose -f docker-compose.prod.yml restart
```

### View Logs
```bash
docker-compose -f docker-compose.prod.yml logs -f [service_name]
```

### Scale Services
```bash
docker-compose -f docker-compose.prod.yml up -d --scale scrollintel-api=3
```

### Database Operations
```bash
# Backup database
pg_dump $DATABASE_URL > backup_$(date +%Y%m%d_%H%M%S).sql

# Restore database
psql $DATABASE_URL < backup_file.sql
```

## Troubleshooting

### High Error Rate
1. Check application logs
2. Verify database connectivity
3. Check external service status
4. Review recent deployments

### High Response Time
1. Check system resources (CPU, memory)
2. Review database query performance
3. Check cache hit rates
4. Verify network connectivity

### Agent Failures
1. Check agent registry status
2. Review orchestration engine logs
3. Verify agent communication channels
4. Check resource allocation

## Emergency Procedures

### Rollback Deployment
```bash
python scripts/rollback-deployment.py --deployment-id {self.deployment_id}
```

### Emergency Shutdown
```bash
docker-compose -f docker-compose.prod.yml down
```

### Contact Information
- **Technical Lead**: tech-lead@company.com
- **DevOps Team**: devops@company.com
- **Emergency Hotline**: emergency@company.com

## Performance Baselines
- **Response Time**: < 1 second (95th percentile)
- **Error Rate**: < 1%
- **Agent Success Rate**: > 95%
- **Uptime**: > 99.9%
"""
        
        with open(docs_dir / "operational_runbook.md", "w") as f:
            f.write(runbook_content)
        
        logger.info(f"‚úÖ Support documentation generated in {docs_dir}")
    
    def _rollback_deployment(self):
        """Rollback deployment to previous state"""
        logger.info("üîÑ Rolling back deployment...")
        
        try:
            # Restore database from backup
            if (self.backup_dir / "database_backup.sql").exists():
                subprocess.run([
                    "psql", os.getenv("DATABASE_URL"),
                    "-f", str(self.backup_dir / "database_backup.sql")
                ], check=True)
            
            # Restore configuration files
            config_backup_path = self.backup_dir / "config"
            if config_backup_path.exists():
                for config_file in config_backup_path.glob("*"):
                    subprocess.run([
                        "cp", str(config_file), "."
                    ], check=True)
            
            # Restart services with previous configuration
            subprocess.run([
                "docker-compose", "-f", "docker-compose.prod.yml",
                "down"
            ], check=True)
            
            subprocess.run([
                "docker-compose", "-f", "docker-compose.prod.yml",
                "up", "-d"
            ], check=True)
            
            logger.info("‚úÖ Rollback completed successfully")
            
        except Exception as e:
            logger.error(f"‚ùå Rollback failed: {str(e)}")
    
    def _update_status(self, status: str):
        """Update deployment status"""
        self.deployment_status["status"] = status
        self.deployment_status["last_updated"] = datetime.now().isoformat()
        
        # Save status to file
        status_file = Path(f"logs/deployment_status_{self.deployment_id}.json")
        with open(status_file, "w") as f:
            json.dump(self.deployment_status, f, indent=2)

def main():
    """Main deployment function"""
    # Ensure logs directory exists
    Path("logs").mkdir(exist_ok=True)
    
    # Load deployment configuration
    config = DeploymentConfig(
        environment=os.getenv("DEPLOYMENT_ENV", "production"),
        enable_blue_green=os.getenv("ENABLE_BLUE_GREEN", "true").lower() == "true",
        enable_canary=os.getenv("ENABLE_CANARY", "true").lower() == "true",
        enable_feature_flags=os.getenv("ENABLE_FEATURE_FLAGS", "true").lower() == "true",
        rollback_on_failure=os.getenv("ROLLBACK_ON_FAILURE", "true").lower() == "true",
        user_acceptance_test=os.getenv("RUN_UAT", "true").lower() == "true",
        monitoring_enabled=os.getenv("ENABLE_MONITORING", "true").lower() == "true"
    )
    
    # Create and run deployer
    deployer = ProductionDeployer(config)
    success = deployer.deploy()
    
    if success:
        logger.info("üéâ Agent Steering System production deployment completed successfully!")
        print("\n" + "="*80)
        print("üöÄ AGENT STEERING SYSTEM PRODUCTION DEPLOYMENT SUCCESSFUL! üöÄ")
        print("="*80)
        print(f"Deployment ID: {deployer.deployment_id}")
        print(f"Environment: {config.environment}")
        print("Features Enabled:")
        print(f"  ‚Ä¢ Blue-Green Deployment: {config.enable_blue_green}")
        print(f"  ‚Ä¢ Canary Rollout: {config.enable_canary}")
        print(f"  ‚Ä¢ Feature Flags: {config.enable_feature_flags}")
        print(f"  ‚Ä¢ Monitoring: {config.monitoring_enabled}")
        print("\nEndpoints:")
        print("  ‚Ä¢ API: http://localhost:8000")
        print("  ‚Ä¢ Frontend: http://localhost:3000")
        print("  ‚Ä¢ Monitoring: http://localhost:3001")
        print("  ‚Ä¢ Metrics: http://localhost:9090")
        print("\nNext Steps:")
        print("  1. Monitor system performance and metrics")
        print("  2. Conduct final user acceptance testing")
        print("  3. Update DNS to point to production")
        print("  4. Configure backup schedules")
        print("  5. Set up alerting notifications")
        print("="*80)
        sys.exit(0)
    else:
        logger.error("‚ùå Agent Steering System production deployment failed!")
        sys.exit(1)

if __name__ == "__main__":
    main()